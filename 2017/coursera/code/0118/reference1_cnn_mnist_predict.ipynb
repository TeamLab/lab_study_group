{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-64103705df8a>:63 in predictint.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "def predictint(imvalue):\n",
    "\n",
    "    \"\"\"\n",
    "    훈련된 모델을 사용하여 하나의 단일 이미지를 받아서 예측한다\n",
    "    :param imvalue:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    훈련시와 동일한 모델을 다시 정의합니다.\n",
    "    자세한 설명은 훈력쪽 소크 코드에서 확인할 수 있습니다.\n",
    "    \"\"\"\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def conv2d(x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    \"\"\"\n",
    "    모델을 saver 를 사용하여 복구합니다.\n",
    "    sess.run(init_op)\n",
    "    saver.restore(sess, \"model2.ckpt\")\n",
    "    \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        saver.restore(sess, \"./model2.ckpt\")\n",
    "        prediction = tf.argmax(y_conv, 1)\n",
    "        return prediction.eval(feed_dict={x: [imvalue], keep_prob: 1.0}, session=sess)\n",
    "\n",
    "\n",
    "def imageprepare(argv):\n",
    "    \"\"\"\n",
    "    로컬에서 이미지를 받아서 Tensorflow 처리 가능한 형태로 변환하는 역할을 수행합니다.\n",
    "    \"\"\"\n",
    "    im = Image.open(argv).convert('L')\n",
    "    width = float(im.size[0])\n",
    "    height = float(im.size[1])\n",
    "    newImage = Image.new('L', (28, 28), (255))  # 우리가 테스트할 네트워크는 28/28 이미지이다\n",
    "\n",
    "    # 입력된 28/28이 아닌 이미지를 28/28로 변환하기 위해 가로 세로 중 어느쪽이 큰지 확인\n",
    "    if width > height:\n",
    "        # 폭이 더 큰 경우 처리 로직\n",
    "        nheight = int(round((20.0 / width * height), 0))  # resize height according to ratio width\n",
    "\n",
    "        # 20/20 이미지로 변환하고\n",
    "        img = im.resize((20, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wtop = int(round(((28 - nheight) / 2), 0))  #\n",
    "        newImage.paste(img, (4, wtop))  # 리사이즈된 이미지를 흰색 바탕의 캔버스에 붙여 넣는다\n",
    "    else:\n",
    "        # 높이가 더 큰경우에 처리 로직\n",
    "        nwidth = int(round((20.0 / height * width), 0))\n",
    "        if (nwidth == 0):\n",
    "            nwidth = 1\n",
    "            # resize and sharpen\n",
    "        img = im.resize((nwidth, 20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wleft = int(round(((28 - nwidth) / 2), 0))\n",
    "        newImage.paste(img, (wleft, 4))\n",
    "\n",
    "    # newImage.save(\"sample.png\")\n",
    "\n",
    "    tv = list(newImage.getdata())  # 픽셀 데이터로 변환\n",
    "\n",
    "    # 255의 RGB 0 흰색, 1 검은색의 이진수로 노멀라이제이션 작업을 수행\n",
    "    tva = [(255 - x) * 1.0 / 255.0 for x in tv]\n",
    "    return tva\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function.\n",
    "    \"\"\"\n",
    "\n",
    "    argv = './number5.png'\n",
    "    imvalue = imageprepare(argv)\n",
    "    predint = predictint(imvalue)\n",
    "    print (predint[0])  # first value in list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ml_python]",
   "language": "python",
   "name": "conda-env-ml_python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
