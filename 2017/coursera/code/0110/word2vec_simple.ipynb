{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very simple word2vec example @ nlintz's tutoral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "print (\"Packages loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "batch_size     = 20\n",
    "embedding_size = 2     # This is just for visualization\n",
    "num_sampled    = 15    # Number of negative examples to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sentences' is <class 'list'> and length is 12.\n"
     ]
    }
   ],
   "source": [
    "# Sample sentences\n",
    "sentences = [\"the quick brown fox jumped over the lazy dog\",\n",
    "            \"I love cats and dogs\",\n",
    "            \"we all love cats and dogs\",\n",
    "            \"cats and dogs are great\",\n",
    "            \"sung likes cats\",\n",
    "            \"she loves dogs\",\n",
    "            \"cats can be very independent\",\n",
    "            \"cats are great companions when they want to be\",\n",
    "            \"cats are playful\",\n",
    "            \"cats are natural hunters\",\n",
    "            \"It's raining cats and dogs\",\n",
    "            \"dogs and cats love sung\"]\n",
    "# 'sentences' is 'list' \n",
    "print (\"'sentences' is %s and length is %d.\" \n",
    "       % (type(sentences), len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'words' is <class 'list'> and length is 62.\n",
      "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', 'I', 'love', 'cats', 'and', 'dogs', 'we', 'all', 'love', 'cats', 'and', 'dogs', 'cats', 'and', 'dogs', 'are', 'great', 'sung', 'likes', 'cats', 'she', 'loves', 'dogs', 'cats', 'can', 'be', 'very', 'independent', 'cats', 'are', 'great', 'companions', 'when', 'they', 'want', 'to', 'be', 'cats', 'are', 'playful', 'cats', 'are', 'natural', 'hunters', \"It's\", 'raining', 'cats', 'and', 'dogs', 'dogs', 'and', 'cats', 'love', 'sung']\n"
     ]
    }
   ],
   "source": [
    "words = \" \".join(sentences).split() \n",
    "print (\"'words' is %s and length is %d.\" % (type(words), len(words)))\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'count' is <class 'list'> and length is 35.\n",
      "Word count of top five is [('cats', 10), ('dogs', 6), ('and', 5), ('are', 4), ('love', 3)]\n",
      "[('cats', 10), ('dogs', 6), ('and', 5), ('are', 4), ('love', 3), ('the', 2), ('be', 2), ('great', 2), ('sung', 2), ('jumped', 1), ('independent', 1), ('dog', 1), ('when', 1), ('natural', 1), ('very', 1), ('playful', 1), ('quick', 1), ('lazy', 1), ('to', 1), ('companions', 1), ('hunters', 1), ('likes', 1), ('brown', 1), ('they', 1), ('she', 1), ('want', 1), ('we', 1), ('fox', 1), ('I', 1), (\"It's\", 1), ('over', 1), ('all', 1), ('can', 1), ('raining', 1), ('loves', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = collections.Counter(words).most_common() \n",
    "print (\"'count' is %s and length is %d.\" % (type(count), len(count)))\n",
    "print ((\"Word count of top five is %s\") % (count[:5]))\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumped']\n",
      "[('cats', 10), ('dogs', 6), ('and', 5)]\n"
     ]
    }
   ],
   "source": [
    "print (words[0:5])\n",
    "print (count[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rdic' is <class 'list'> and length is 35.\n",
      "'dic' is <class 'dict'> and length is 35.\n"
     ]
    }
   ],
   "source": [
    "rdic = [i[0] for i in count] #reverse dic, idx -> word\n",
    "dic = {w: i for i, w in enumerate(rdic)} #dic, word -> id\n",
    "voc_size = len(dic) # Number of vocabulary \n",
    "print (\"'rdic' is %s and length is %d.\" % (type(rdic), len(rdic)))\n",
    "print (\"'dic' is %s and length is %d.\" % (type(dic), len(dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'dogs', 'and', 'are', 'love', 'the', 'be', 'great', 'sung', 'jumped', 'independent', 'dog', 'when', 'natural', 'very', 'playful', 'quick', 'lazy', 'to', 'companions', 'hunters', 'likes', 'brown', 'they', 'she', 'want', 'we', 'fox', 'I', \"It's\", 'over', 'all', 'can', 'raining', 'loves']\n"
     ]
    }
   ],
   "source": [
    "print (rdic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 5, 'jumped': 9, 'independent': 10, 'great': 7, 'when': 12, 'natural': 13, 'very': 14, 'be': 6, 'playful': 15, 'quick': 16, 'lazy': 17, 'to': 18, 'companions': 19, 'hunters': 20, 'all': 31, 'cats': 0, 'dog': 11, 'likes': 21, 'brown': 22, 'they': 23, 'she': 24, 'want': 25, 'dogs': 1, 'we': 26, 'fox': 27, 'are': 3, 'sung': 8, 'I': 28, \"It's\": 29, 'over': 30, 'love': 4, 'and': 2, 'can': 32, 'raining': 33, 'loves': 34}\n",
      "{0: 'cats', 1: 'dogs', 2: 'and', 3: 'are', 4: 'love', 5: 'the', 6: 'be', 7: 'great', 8: 'sung', 9: 'jumped', 10: 'independent', 11: 'dog', 12: 'when', 13: 'natural', 14: 'very', 15: 'playful', 16: 'quick', 17: 'lazy', 18: 'to', 19: 'companions', 20: 'hunters', 21: 'likes', 22: 'brown', 23: 'they', 24: 'she', 25: 'want', 26: 'we', 27: 'fox', 28: 'I', 29: \"It's\", 30: 'over', 31: 'all', 32: 'can', 33: 'raining', 34: 'loves'}\n"
     ]
    }
   ],
   "source": [
    "print (dic)\n",
    "revierse_dic = {v: k for k, v in dic.items()}\n",
    "print(revierse_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (rdic[0])\n",
    "print (dic['cats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data' is <class 'list'> and length is 62.\n",
      "Sample data: numbers: [5, 16, 22, 27, 9, 30, 5, 17, 11, 28] / words: ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', 'I']\n"
     ]
    }
   ],
   "source": [
    "data = [dic[word] for word in words]\n",
    "print (\"'data' is %s and length is %d.\" % (type(data), len(data)))\n",
    "print('Sample data: numbers: %s / words: %s'% (data[:10], [rdic[t] for t in data[:10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW and SKIP Gram\n",
    "\n",
    "[REFERENCE](http://nohhj.blogspot.kr/2015/08/word-embedding.html)\n",
    "\n",
    "![cbow and skip-gram](http://4.bp.blogspot.com/-qV1SVTB1zjQ/VcxHhKjxx6I/AAAAAAAAACU/UvsM0r7s9_8/s1600/1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context pairs: [[[5, 22], 16], [[16, 27], 22], [[22, 9], 27], [[27, 30], 9], [[9, 5], 30], [[30, 17], 5], [[5, 11], 17], [[17, 28], 11], [[11, 4], 28], [[28, 0], 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('great', 'we', 'I')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_pairs = [];\n",
    "for i in range(1, len(data)-1) :\n",
    "    cbow_pairs.append([[data[i-1], data[i+1]], data[i]]);\n",
    "print('Context pairs: %s' % (cbow_pairs[:10]))\n",
    "\n",
    "data[28]\n",
    "# the quick brown fox jumped over the lazy dog\n",
    "revierse_dic[7], revierse_dic[26], revierse_dic[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'skip_gram_pairs' is <class 'list'> and length is 120.\n",
      "skip-gram pairs [[16, 5], [16, 22], [22, 16], [22, 27], [27, 22]]\n",
      "I great\n",
      "I we\n"
     ]
    }
   ],
   "source": [
    "# (quick, the), (quick, brown), (brown, quick), (brown, fox), ...\n",
    "# the quick brown fox jumped over the lazy dog\n",
    "\n",
    "\n",
    "skip_gram_pairs = [];\n",
    "for c in cbow_pairs:\n",
    "    skip_gram_pairs.append([c[1], c[0][0]])\n",
    "    skip_gram_pairs.append([c[1], c[0][1]])\n",
    "    \n",
    "print (\"'skip_gram_pairs' is %s and length is %d.\"\n",
    "       % (type(skip_gram_pairs), len(skip_gram_pairs)))\n",
    "print('skip-gram pairs', skip_gram_pairs[:5])\n",
    "\n",
    "# the quick brown fox jumped over the lazy dog\n",
    "print(revierse_dic[28], revierse_dic[7])\n",
    "print(revierse_dic[28], revierse_dic[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches (x, y) [29, 12, 5] [[33], [23], [17]]\n",
      "It's raining\n",
      "when they\n",
      "the lazy\n"
     ]
    }
   ],
   "source": [
    "def generate_batch(size):\n",
    "    assert size < len(skip_gram_pairs)\n",
    "    x_data=[]\n",
    "    y_data = []\n",
    "    r = np.random.choice(range(len(skip_gram_pairs)), size, replace=False)\n",
    "    for i in r:\n",
    "        x_data.append(skip_gram_pairs[i][0])  # n dim\n",
    "        y_data.append([skip_gram_pairs[i][1]])  # n, 1 dim\n",
    "    return x_data, y_data\n",
    "\n",
    "# generate_batch test\n",
    "x, y = generate_batch(3)\n",
    "print ('Batches (x, y)', x,y)\n",
    "\n",
    "print(revierse_dic[x[0]], revierse_dic[y[0][0]])\n",
    "print(revierse_dic[x[1]], revierse_dic[y[1][0]])\n",
    "print(revierse_dic[x[2]], revierse_dic[y[2][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input data\n",
    "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "# need to shape [batch_size, 1] for nn.nce_loss\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "# Ops and variables pinned to the CPU because of missing GPU implementation\n",
    "with tf.device('/cpu:0'):\n",
    "    # Look up embeddings for inputs.\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs) # lookup table\n",
    "\n",
    "# Construct the variables for the NCE loss\n",
    "nce_weights = tf.Variable(\n",
    "    tf.random_uniform([voc_size, embedding_size],-1.0, 1.0))\n",
    "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
    "\n",
    "# Compute the average NCE loss for the batch.\n",
    "# This does the magic:\n",
    "#   tf.nn.nce_loss(weights, biases, inputs, labels, num_sampled, num_classes ...)\n",
    "# It automatically draws negative samples when we evaluate the loss.\n",
    "loss = tf.reduce_mean(\n",
    "  tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n",
    "                 num_sampled, voc_size))\n",
    "\n",
    "# Use the adam optimizer\n",
    "train_op = tf.train.AdamOptimizer(1e-1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-c84d511d3853>:5 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas SGEMM launch failed : a.shape=(20, 2), b.shape=(15, 2), m=20, n=15, k=2\n\t [[Node: nce_loss_3/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_lookup_3/_41, nce_loss_3/Slice_2)]]\n\t [[Node: Adam_3/update_Variable_10/group_deps/_50 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_334_Adam_3/update_Variable_10/group_deps\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'nce_loss_3/MatMul_1', defined at:\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-819b0f25fd47>\", line 23, in <module>\n    num_sampled, voc_size))\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/nn.py\", line 1336, in nce_loss\n    name=name)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/nn.py\", line 1219, in _compute_sampled_logits\n    inputs, sampled_w, transpose_b=True) + sampled_b\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(20, 2), b.shape=(15, 2), m=20, n=15, k=2\n\t [[Node: nce_loss_3/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_lookup_3/_41, nce_loss_3/Slice_2)]]\n\t [[Node: Adam_3/update_Variable_10/group_deps/_50 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_334_Adam_3/update_Variable_10/group_deps\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(20, 2), b.shape=(15, 2), m=20, n=15, k=2\n\t [[Node: nce_loss_3/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_lookup_3/_41, nce_loss_3/Slice_2)]]\n\t [[Node: Adam_3/update_Variable_10/group_deps/_50 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_334_Adam_3/update_Variable_10/group_deps\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c84d511d3853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         _, loss_val = sess.run([train_op, loss],\n\u001b[0;32m---> 10\u001b[0;31m                 feed_dict={train_inputs: batch_inputs, train_labels: batch_labels})\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss at \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Report the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(20, 2), b.shape=(15, 2), m=20, n=15, k=2\n\t [[Node: nce_loss_3/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_lookup_3/_41, nce_loss_3/Slice_2)]]\n\t [[Node: Adam_3/update_Variable_10/group_deps/_50 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_334_Adam_3/update_Variable_10/group_deps\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'nce_loss_3/MatMul_1', defined at:\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-819b0f25fd47>\", line 23, in <module>\n    num_sampled, voc_size))\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/nn.py\", line 1336, in nce_loss\n    name=name)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/nn.py\", line 1219, in _compute_sampled_logits\n    inputs, sampled_w, transpose_b=True) + sampled_b\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/teamlab/miniconda3/envs/nrf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(20, 2), b.shape=(15, 2), m=20, n=15, k=2\n\t [[Node: nce_loss_3/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_lookup_3/_41, nce_loss_3/Slice_2)]]\n\t [[Node: Adam_3/update_Variable_10/group_deps/_50 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_334_Adam_3/update_Variable_10/group_deps\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # Initializing all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for step in range(100):\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size)\n",
    "        _, loss_val = sess.run([train_op, loss],\n",
    "                feed_dict={train_inputs: batch_inputs, train_labels: batch_labels})\n",
    "        if step % 10 == 0:\n",
    "          print(\"Loss at \", step, loss_val) # Report the loss\n",
    "\n",
    "    # Final embeddings are ready for you to use. Need to normalize for practical use\n",
    "    trained_embeddings = embeddings.eval()\n",
    "\n",
    "# Show word2vec if dim is 2\n",
    "if trained_embeddings.shape[1] == 2:\n",
    "    labels = rdic[:10] # Show top 10 words\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = trained_embeddings[i,:]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2),\n",
    "            textcoords='offset points', ha='right', va='bottom')\n",
    "    plt.savefig(\"word2vec.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [nrf]",
   "language": "python",
   "name": "Python [nrf]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
