{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "\n",
    "L3 = tf.reshape(L3,[100, 1, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "batch_size = 100\n",
    "cell = tf.contrib.rnn.GRUCell(num_units=hidden_size)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(\n",
    "    cell, L3, initial_state=initial_state, dtype=tf.float32)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=outputs))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "total_batch_train = int(mnist.train.num_examples / batch_size)\n",
    "total_batch_test = int(mnist.test.num_examples / batch_size)\n",
    "output_list = []\n",
    "batch_y = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(1):\n",
    "        total_cost = 0\n",
    "        for i in range(total_batch_train):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
    "            batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "            _, cost_val,asd = sess.run([train, loss,outputs],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob: 0.7})\n",
    "    for j in range(total_batch_test):\n",
    "        batch_xs, batch_ys = mnist.test.next_batch(batch_size)\n",
    "        # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        outout = sess.run(outputs,\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob: 1.0})\n",
    "        output_list.append(outout)\n",
    "        batch_y.append(batch_ys)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_prediction = np.reshape(output_list[0],[100,10])\n",
    "for i in range(1,100):\n",
    "     convert_prediction = np.vstack((convert_prediction,np.reshape(output_list[i],[100,10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99999952, -1.        , -0.99999976, ...,  0.99999982,\n",
       "        -0.99999988, -1.        ],\n",
       "       [-0.99999994, -0.99697554,  1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       [-0.99983382,  0.99998736, -0.99978787, ..., -0.99988323,\n",
       "        -0.99998266, -0.99998337],\n",
       "       ..., \n",
       "       [-0.9999997 , -0.99999994, -0.99998999, ..., -0.99989849,\n",
       "        -0.99999851, -0.9999783 ],\n",
       "       [-0.99999833, -0.99999994, -0.99999988, ..., -0.99999994,\n",
       "        -0.98441952, -0.99999982],\n",
       "       [-1.        , -0.99999988, -0.99999982, ..., -0.99999976,\n",
       "        -1.        , -1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_batch_y = np.reshape(np.array(batch_y),[10000,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_batch_y[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99999952, -1.        , -0.99999976, ...,  0.99999982,\n",
       "        -0.99999988, -1.        ],\n",
       "       [-0.99999994, -0.99697554,  1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       [-0.99983382,  0.99998736, -0.99978787, ..., -0.99988323,\n",
       "        -0.99998266, -0.99998337],\n",
       "       ..., \n",
       "       [-0.9999997 , -0.99999994, -0.99998999, ..., -0.99989849,\n",
       "        -0.99999851, -0.9999783 ],\n",
       "       [-0.99999833, -0.99999994, -0.99999988, ..., -0.99999994,\n",
       "        -0.98441952, -0.99999982],\n",
       "       [-1.        , -0.99999988, -0.99999982, ..., -0.99999976,\n",
       "        -1.        , -1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.argmax(convert_prediction, axis=1)\n",
    "real = np.argmax(convert_batch_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(prediction == real)/10000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
