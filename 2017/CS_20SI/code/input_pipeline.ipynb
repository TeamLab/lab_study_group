{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = tf.FIFOQueue(3, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = q.enqueue_many(([0.,0.,0.,],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = q.dequeue()\n",
    "y = x+1\n",
    "q_inc = q.enqueue([y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "NUM_THREADS = 4\n",
    "# Generating some simple data\n",
    "# create 1000 random samples, each is a 1D array from the normal distribution (10, 1)\n",
    "data = 10 * np . random . randn ( N_SAMPLES , 4 ) + 1\n",
    "# create 1000 random labels of 0 and 1\n",
    "target = np . random . randint ( 0 , 2 , size = N_SAMPLES )\n",
    "queue = tf . FIFOQueue ( capacity = 50 , dtypes =[ tf . float32 , tf . int32 ], shapes =[[ 4 ], []])\n",
    "enqueue_op = queue . enqueue_many ([ data , target ])\n",
    "dequeue_op = queue . dequeue ()\n",
    "# create NUM_THREADS to do enqueue\n",
    "qr = tf . train . QueueRunner ( queue , [ enqueue_op ] * NUM_THREADS)\n",
    "with tf . Session () as sess:\n",
    "# Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf . train . Coordinator ()\n",
    "    enqueue_threads = qr . create_threads ( sess , coord = coord , start = True)\n",
    "    for step in range ( 100 ): # do to 100 iterations\n",
    "        if coord . should_stop ():\n",
    "            break\n",
    "        data_batch , label_batch = sess . run ( dequeue_op)\n",
    "    coord . request_stop ()\n",
    "    coord . join ( enqueue_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-37e1ba358d20>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-37e1ba358d20>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    if ... some condition ...:\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "# thread body: loop until the coordinator indicates a stop was requested.\n",
    "# if some condition becomes true, ask the coordinator to stop.\n",
    "def my_loop ( coord ):\n",
    "    while not coord . should_stop ():\n",
    "        print(\"1\")\n",
    "    if ... some condition ...:\n",
    "        coord . request_stop ()\n",
    "# main code: create a coordinator.\n",
    "coord = tf . Coordinator ()\n",
    "# create 10 threads that run 'my_loop()'\n",
    "# you can also create threads using QueueRunner as the example above\n",
    "threads = [ threading . Thread ( target = my_loop , args =( coord ,)) for _ in xrange ( 10 )]\n",
    "# start the threads and wait for all of them to stop.\n",
    "for t in threads :\n",
    "    t . start ()\n",
    "coord . join ( threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf . TextLineReader\n",
    "Outputs the lines of a file delimited by newlines\n",
    "<br>E . g . text files , CSV files\n",
    "\n",
    "### tf . FixedLengthRecordReader\n",
    "Outputs the entire file when all files have same fixed lengths\n",
    "<br>E . g . each MNIST file has 28 x 28 pixels , CIFAR - 10 32 x 32 x 3\n",
    "\n",
    "### tf . WholeFileReader\n",
    "Outputs the entire file content. This is useful when each file contains a sample\n",
    "\n",
    "### tf . TFRecordReader\n",
    "Reads samples from TensorFlow ' s own binary format ( TFRecord)\n",
    "\n",
    "### tf . ReaderBase\n",
    "Allows you to create your own readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train . string_input_producer ([ \"heart.csv\" ])\n",
    "reader = tf . TextLineReader (skip_header_lines=1)\n",
    "# it means you choose to skip the first line for every file in the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key , value = reader . read ( filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-f95051c6a491>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-f95051c6a491>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    key = data/heart.csv:2\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "key = data/heart.csv:2\n",
    "value = 144 , 0.01 , 4.41 , 28.61 , Absent , 55 , 28.87 , 2.06 , 63 ,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-7a3571ed0cf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfilename_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_input_producer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextLineReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskip_header_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# skip the first line in the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "reader = tf.TextLineReader(skip_header_lines = 1) # skip the first line in the file\n",
    "key, value = reader.read (filename_queue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord = coord)\n",
    "    print(sess.run(key)) # data / heart . csv :2\n",
    "    print(sess.run(value)) # 144 , 0.01 , 4.41 , 28.61 , Absent , 55 , 28.87 , 2.06 , 63 ,1\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
